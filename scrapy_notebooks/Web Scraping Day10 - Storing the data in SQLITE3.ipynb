{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e3d1a4",
   "metadata": {},
   "source": [
    "# STORING THE DATA IN SQLITE3 DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc8aa4",
   "metadata": {},
   "source": [
    "### By - Nilutpal Das"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a889596",
   "metadata": {},
   "source": [
    "# NOTE : the process shown in this section is built to be run in dedicated IDE also inside a specific folder discussed in the previous notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92100e",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "### SQLite is a lightweight and self-contained database engine that does not require a separate server process or configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c8737",
   "metadata": {},
   "source": [
    "# NOTE : the database.py file and myquotes.db files are for introductory demo purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262ebba",
   "metadata": {},
   "source": [
    "## database.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd03837",
   "metadata": {},
   "source": [
    "### 1. create a database.py file inside the web scraping folder and now running this code will create a database and also create a table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8c63b34",
   "metadata": {},
   "source": [
    "# BASICS OF SQLITE3 DATABASE\n",
    "\n",
    "# importing the libraries\n",
    "import sqlite3\n",
    "\n",
    "# creating the database or creating connection w/ database\n",
    "conn = sqlite3.connect('myquotes.db')\n",
    "\n",
    "# creating  a cursor inside a connection\n",
    "curr = conn.cursor()\n",
    "\n",
    "# creating tables\n",
    "curr.execute(\"\"\"create table quotes_db(\n",
    "                quote text,\n",
    "                author text,\n",
    "                tag text\n",
    "            )\"\"\")\n",
    "\n",
    "# executing the sql commands\n",
    "conn.commit()\n",
    "\n",
    "# closing the connection after execution\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1f22e",
   "metadata": {},
   "source": [
    "### 2. after running the previous code which has the code to create database and tables, by running this code will insert the data into that created table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3749866c",
   "metadata": {},
   "source": [
    "# BASICS OF SQLITE3 DATABASE\n",
    "\n",
    "# importing the libraries\n",
    "import sqlite3\n",
    "\n",
    "# creating the database or creating connection w/ database\n",
    "conn = sqlite3.connect('myquotes.db')\n",
    "\n",
    "# creating  a cursor inside a connection\n",
    "curr = conn.cursor()\n",
    "\n",
    "# inserting data inside the tables\n",
    "curr.execute(\"\"\"insert into quotes_db values ('Python is awesome', 'PythonCommunity', 'Python')\"\"\")\n",
    "\n",
    "# executing the sql commands\n",
    "conn.commit()\n",
    "\n",
    "# closing the connection after execution\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b48511",
   "metadata": {},
   "source": [
    "### 3. till here all things are working good that means our demo session on SQLITE3 is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91940c13",
   "metadata": {},
   "source": [
    "### 4. so to do that first we have to create a similar program inside pipelines.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65297e",
   "metadata": {},
   "source": [
    "# NOTE : here after there is no need of the database.py file and myquotes.db , delete both files as we are directly working on pipelines.py which has all the necessary tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352029b9",
   "metadata": {},
   "source": [
    "## pipelines.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765df46",
   "metadata": {},
   "source": [
    "### 5. similar to the demo sessions create few funtions inside class WebscrapyPipeline : <br> 1. function for creating database <br> 2. function for creating table <br> 3. function for fetching the scraped data as item <br> 4. function for inserting scraped data into table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d67809af",
   "metadata": {},
   "source": [
    "# Define your item pipelines here\n",
    "#\n",
    "# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n",
    "# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "\n",
    "\n",
    "# useful for handling different item types with a single interface\n",
    "import sqlite3\n",
    "from itemadapter import ItemAdapter\n",
    "\n",
    "\n",
    "class WebscrapyPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.create_connection()\n",
    "        self.create_table()\n",
    "    \n",
    "    def create_connection(self):\n",
    "        self.conn = sqlite3.connect(\"myquotes.db\")\n",
    "        self.curr = self.conn.cursor()\n",
    "    \n",
    "    def create_table(self):\n",
    "        self.curr.execute(\"\"\"DROP TABLE IF EXISTS quote_tb\"\"\")\n",
    "        self.curr.execute(\"\"\"CREATE TABLE quotes_tb(\n",
    "                        quote text,\n",
    "                        author text,\n",
    "                        tag text\n",
    "                        )\"\"\")\n",
    "        \n",
    "    def process_item(self, item, spider):\n",
    "        \n",
    "        self.store_db(item)\n",
    "        print(\"Pipeline is working successfully\")\n",
    "\n",
    "        return item\n",
    "\n",
    "    def store_db(self,item):\n",
    "        self.curr.execute(\"\"\"INSERT INTO quotes_tb VALUES (?,?,?)\"\"\",\n",
    "        (\n",
    "                item['quote'][0],\n",
    "                item['author'][0],\n",
    "                item['tag'][0]\n",
    "        ))\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071adf27",
   "metadata": {},
   "source": [
    "### 5. and by running the scrapy project once again, you'll see that the pipelines.py is working and it has successfully stored the scraped data into myquotes.db in sqlite3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
